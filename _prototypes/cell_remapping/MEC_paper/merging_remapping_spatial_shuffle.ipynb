{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, mannwhitneyu, wilcoxon, ttest_rel, ttest_ind\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from matplotlib.colors import ColorConverter\n",
    "\n",
    "remap_path = os.getcwd()\n",
    "prototype_path = os.path.abspath(os.path.join(remap_path, os.pardir))\n",
    "project_path = os.path.abspath(os.path.join(prototype_path, os.pardir))\n",
    "lab_path = os.path.abspath(os.path.join(project_path, os.pardir))\n",
    "sys.path.append(lab_path)\n",
    "# os.chdir(project_path)\n",
    "# sys.path.append(project_path)\n",
    "# print(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _prototypes.cell_remapping.src.MEC_naming import MEC_naming_format, extract_name_mec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv path\n",
    "# remapping_csv_path = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\full_32_permute.xlsx\"\n",
    "\n",
    "reg_csv = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\GusData\\corrected_csvs\\regular_corrected_combined.xlsx\"\n",
    "# reg_csv = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\GusData\\norm_pos_and_fr_csvs\\regular_unnorm_pos_combined.xlsx\"\n",
    "# temp_csv = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\GusData\\corrected_csvs\\temporal_corrected_combined.xlsx\"\n",
    "sd_csv = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\GusData\\norm_pos_and_fr_csvs\\filtered_any_ses_greater.xlsx\"\n",
    "\n",
    "\n",
    "regular_df = pd.read_excel(reg_csv)\n",
    "# temporal_df = pd.read_excel(temp_csv)\n",
    "sd_df = pd.read_excel(sd_csv)\n",
    "\n",
    "# sort by 'signature' column\n",
    "regular_df = regular_df.sort_values(by=['signature'])\n",
    "# temporal_df = temporal_df.sort_values(by=['signature'])\n",
    "# temporal_df_valid_columns = ['emd', 'emd_z', 'emd_quantile', 'emd_mean', 'emd_std']\n",
    "sd_df_drop_columns = ['whole_wass', 'z_score', 'base_mean', 'base_std', 'median', 'mad', 'quantile', 'plower',\n",
    "                       'phigher', 'ptwotail', 'sd_wass', 'sd_z_score', 'sd_quantile', 'sd_base_mean',\n",
    "                        'sd_base_std', 'sd_median', 'sd_mad']\n",
    "# sd_df_valid_columns = ['sd_wass', 'sd_z_score', 'sd_quantile', 'sd_base_mean', 'sd_base_std', 'sd_median', 'sd_mad']\n",
    "# sd_df_drop_columns = ['sd_wass', 'sd_z_score', 'sd_quantile', 'sd_base_mean', 'sd_base_std', 'sd_median', 'sd_mad']\n",
    "sd_df = sd_df.drop(columns=sd_df_drop_columns)\n",
    "sd_df = sd_df.sort_values(by=['signature'])\n",
    "# temporal_df = temporal_df[temporal_df_valid_columns]\n",
    "# sd_df = sd_df[sd_df_valid_columns]\n",
    "regular_df = regular_df[sd_df_drop_columns]\n",
    "\n",
    "# reset index\n",
    "regular_df = regular_df.reset_index(drop=True)\n",
    "# temporal_df = temporal_df.reset_index(drop=True)\n",
    "sd_df = sd_df.reset_index(drop=True)\n",
    "\n",
    "# horizontal concatenation\n",
    "remapping_df = pd.concat([regular_df, sd_df], axis=1)\n",
    "# remapping_df = pd.concat([regular_df, temporal_df, sd_df], axis=1)\n",
    "# remapping_df = pd.concat([sd_df, regular_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# load csv\n",
    "# remapping_df = pd.read_excel(remapping_csv_path)\n",
    "\n",
    "# csv path\n",
    "shuffle_spatial_path = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\MEC_spatial_shuffles_combined_new.xlsx\"\n",
    "\n",
    "# load csv\n",
    "shuffle_spatial_df = pd.read_excel(shuffle_spatial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle_spatial_df['p_value_information'] = 1 - shuffle_spatial_df['p_value_information']\n",
    "# shuffle_spatial_df['p_value_sparsity'] = 1 - shuffle_spatial_df['p_value_sparsity']\n",
    "# shuffle_spatial_df['p_value_selectivity'] = 1 - shuffle_spatial_df['p_value_selectivity']\n",
    "# shuffle_spatial_df['p_value_coherence'] = 1 - shuffle_spatial_df['p_value_coherence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to match neurofunc and remapping\n",
    "import re\n",
    "from scripts.batch_map.LEC_naming import LEC_naming_format, extract_name_lec\n",
    "\n",
    "def _check_single_format(filename, fformat, fxn):\n",
    "    if re.match(str(fformat), str(filename)) is not None:\n",
    "        return list(fxn(filename))\n",
    "\n",
    "# For neurofunc need to add extract, date, depth, name, stim \n",
    "# iterate thru rows of shuffle_spatial_df and extract from signature\n",
    "for i, row in shuffle_spatial_df.iterrows():\n",
    "    # extract\n",
    "    fname = row['Session']\n",
    "    name = extract_name_mec(fname)\n",
    "    formats = MEC_naming_format\n",
    "    for fformat in list(formats.keys()):\n",
    "        checked = _check_single_format(fname, fformat, formats[fformat])\n",
    "        if checked is not None:\n",
    "            break\n",
    "    stim, depth, name, date = checked\n",
    "    \n",
    "    shuffle_spatial_df.at[i, 'date'] = date\n",
    "    shuffle_spatial_df.at[i, 'depth'] = depth\n",
    "    shuffle_spatial_df.at[i, 'name'] = name\n",
    "    shuffle_spatial_df.at[i, 'stim'] = stim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the common columns\n",
    "neurofunc_row_identifiers = ['name', 'Tetrode', 'Cell ID']\n",
    "remapping_row_identifiers = ['name', 'tetrode', 'unit_id']\n",
    "\n",
    "for row in neurofunc_row_identifiers:\n",
    "    shuffle_spatial_df[row] = shuffle_spatial_df[row].astype(str)\n",
    "for row in remapping_row_identifiers:\n",
    "    remapping_df[row] = remapping_df[row].astype(str)\n",
    "shuffle_spatial_df['Session'] = shuffle_spatial_df['Session'].astype(str)\n",
    "remapping_df['signature'] = remapping_df['signature'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create an empty list to store the merged rows\n",
    "# merged_rows = []\n",
    "\n",
    "# # Iterate through each row in remapping_df\n",
    "# counter = 0\n",
    "# for remapping_row in remapping_df.itertuples(index=False):\n",
    "#     # Extract the identifiers from the remapping row\n",
    "#     remapping_identifiers = [getattr(remapping_row, col) for col in remapping_row_identifiers]\n",
    "\n",
    "#     # Find the matching row in shuffle_spatial_df based on the identifiers\n",
    "#     matching_row = shuffle_spatial_df.loc[\n",
    "#         (shuffle_spatial_df[neurofunc_row_identifiers] == remapping_identifiers).all(axis=1)\n",
    "#     ]\n",
    "\n",
    "#     # Check if a matching row was found\n",
    "#     if len(matching_row) == 0:\n",
    "#         print(\"Found {} matching rows for {}\".format(len(matching_row), remapping_identifiers))\n",
    "#         print(matching_row['Session'], getattr(remapping_row, 'signature'))\n",
    "#         # stop()\n",
    "#     elif len(matching_row) > 1:\n",
    "#         # check all rows are matching on spatial info score \n",
    "#         print(matching_row)\n",
    "#         prev = None\n",
    "#         for i, row in matching_row.iterrows():\n",
    "#             if prev is None:\n",
    "#                 prev = row['spike_count']\n",
    "#             else:\n",
    "#                 if prev != row['spike_count']:\n",
    "#                     print('multiple matches')\n",
    "#                     print(matching_row)\n",
    "#                     # stop()\n",
    "        \n",
    "#     # Join the matching rows\n",
    "#     # merged_row = pd.concat([matching_row, pd.DataFrame([remapping_row], columns=remapping_df.columns)], axis=1)\n",
    "#     merged_rows.append(matching_row)\n",
    "#     counter += 1\n",
    "\n",
    "#     if len(merged_rows) != counter:\n",
    "#         print('error {} != {}'.format(len(merged_rows), counter))\n",
    "#         print(matching_row)\n",
    "\n",
    "\n",
    "# # Create the merged dataframe\n",
    "# merged_df = pd.concat(merged_rows, ignore_index=True)\n",
    "\n",
    "# # Print the merged dataframe\n",
    "# # print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle_spatial_df['isSpatial'] = 0\n",
    "# spatial_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_information'] < 0.05]\n",
    "# spatial_identifiers = spatial_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# for i, row in spatial_identifiers.iterrows():\n",
    "#     matching_rows = remapping_df[remapping_row_identifiers].eq(row[neurofunc_row_identifiers]).all(axis=1)\n",
    "#     remapping_df.loc[matching_rows, 'isSpatial'] = 1\n",
    "\n",
    "# shuffle_spatial_df['isSparse'] = 0\n",
    "# sparsity_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_sparsity'] < 0.05]\n",
    "# sparsity_identifiers = sparsity_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# for i, row in sparsity_identifiers.iterrows():\n",
    "#     matching_rows = remapping_df[remapping_row_identifiers].eq(row[neurofunc_row_identifiers]).all(axis=1)\n",
    "#     remapping_df.loc[matching_rows, 'isSparse'] = 1\n",
    "\n",
    "# shuffle_spatial_df['isSelective'] = 0\n",
    "# selectivity_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_selectivity'] < 0.05]\n",
    "# selectivity_identifiers = selectivity_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# for i, row in selectivity_identifiers.iterrows():\n",
    "#     matching_rows = remapping_df[remapping_row_identifiers].eq(row[neurofunc_row_identifiers]).all(axis=1)\n",
    "#     remapping_df.loc[matching_rows, 'isSelective'] = 1\n",
    "\n",
    "# shuffle_spatial_df['isCoherent'] = 0\n",
    "# coherence_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_coherence'] < 0.05]\n",
    "# coherence_identifiers = coherence_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# for i, row in coherence_identifiers.iterrows():\n",
    "#     matching_rows = remapping_df[remapping_row_identifiers].eq(row[neurofunc_row_identifiers]).all(axis=1)\n",
    "#     remapping_df.loc[matching_rows, 'isCoherent'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_id_dict = {}\n",
    "unq_names = shuffle_spatial_df['name'].unique()\n",
    "unq_name_counts = {x:1 for x in unq_names}\n",
    "for ses_id in np.sort(shuffle_spatial_df['Session'].unique()):\n",
    "    nme = ses_id.split('_')[0]\n",
    "    ses_id_dict[ses_id] = 'session_' + str(unq_name_counts[nme])\n",
    "    unq_name_counts[nme] += 1\n",
    "\n",
    "shuffle_spatial_df['session_id'] = ''\n",
    "shuffle_spatial_df['group'] = ''\n",
    "\n",
    "for i in range(len(shuffle_spatial_df)):\n",
    "    shuffle_spatial_df.loc[i,'session_id'] = ses_id_dict[shuffle_spatial_df.iloc[i]['Session']]\n",
    "\n",
    "app_ki = ['1-13', '1-14', '1a27', '1-30', '1a35', '1a37']\n",
    "control = ['1-20', '1-24', '1-25', '1-28', '1-34', '1a23', '1a40']\n",
    "\n",
    "for i in range(len(remapping_df)):\n",
    "    nme = remapping_df.iloc[i]['name']\n",
    "    print()\n",
    "    if nme in control:\n",
    "        remapping_df.loc[i,'group'] = 'control'\n",
    "    else:\n",
    "        assert nme in app_ki\n",
    "        remapping_df.loc[i,'group'] = 'app_ki'\n",
    "    ses1 = eval(remapping_df.iloc[i]['session_ids'])[0]\n",
    "    ses2 = eval(remapping_df.iloc[i]['session_ids'])[1]\n",
    "\n",
    "    ses1_match = shuffle_spatial_df.loc[(shuffle_spatial_df['session_id'] == ses1) & (shuffle_spatial_df['name'] == remapping_df.iloc[i]['name']) & (shuffle_spatial_df['Tetrode'] == remapping_df.iloc[i]['tetrode']) & (shuffle_spatial_df['Cell ID'] == remapping_df.iloc[i]['unit_id'])]\n",
    "    ses2_match = shuffle_spatial_df.loc[(shuffle_spatial_df['session_id'] == ses2) & (shuffle_spatial_df['name'] == remapping_df.iloc[i]['name']) & (shuffle_spatial_df['Tetrode'] == remapping_df.iloc[i]['tetrode']) & (shuffle_spatial_df['Cell ID'] == remapping_df.iloc[i]['unit_id'])]\n",
    "\n",
    "    assert len(ses1_match) == 1, 'ses1_match: {}'.format(len(ses1_match))\n",
    "    assert len(ses2_match) == 1, 'ses2_match: {}'.format(len(ses2_match))\n",
    "\n",
    "    for ky in ['information', 'sparsity', 'selectivity', 'coherence']:\n",
    "        score_origin_session = ses1_match.iloc[0][ky]\n",
    "        score_target_session = ses2_match.iloc[0][ky]\n",
    "        remapping_df.loc[i, ky + '_origin_session'] = score_origin_session\n",
    "        remapping_df.loc[i, ky + '_target_session'] = score_target_session\n",
    "\n",
    "        shuffled_score_mean_origin_session = ses1_match.iloc[0]['shuffled_' + ky + '_mean']\n",
    "        shuffled_score_mean_target_session = ses2_match.iloc[0]['shuffled_' + ky + '_mean']\n",
    "        remapping_df.loc[i, ky + '_reference_mean_origin_session'] = shuffled_score_mean_origin_session\n",
    "        remapping_df.loc[i, ky + '_reference_mean_target_session'] = shuffled_score_mean_target_session\n",
    "\n",
    "        shuffled_score_sd_origin_session = ses1_match.iloc[0]['shuffled_' + ky + '_std']\n",
    "        shuffled_score_sd_target_session = ses2_match.iloc[0]['shuffled_' + ky + '_std']\n",
    "        remapping_df.loc[i, ky + '_reference_sd_origin_session'] = shuffled_score_sd_origin_session\n",
    "        remapping_df.loc[i, ky + '_reference_sd_target_session'] = shuffled_score_sd_target_session\n",
    "\n",
    "        shuffled_score_p_value_origin_session = ses1_match.iloc[0]['p_value_' + ky]\n",
    "        shuffled_score_p_value_target_session = ses2_match.iloc[0]['p_value_' + ky]\n",
    "        remapping_df.loc[i, ky + '_quantile_origin_session'] = shuffled_score_p_value_origin_session\n",
    "        remapping_df.loc[i, ky + '_quantile_target_session'] = shuffled_score_p_value_target_session\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save as csv\n",
    "# remapping_df.to_excel('remapping_corrected_shuffle_merged.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping_df['isSpatial'] = 0\n",
    "\n",
    "# any session pvalue < 0.05 then cell is spatial\n",
    "spatial_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_information'] < 0.05]\n",
    "spatial_identifiers = spatial_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "\n",
    "# only first session pvalue < 0.05 then cell is spatial\n",
    "# spatial_identifiers = shuffle_spatial_df.groupby(neurofunc_row_identifiers).agg({'p_value_information': 'first'}).reset_index()\n",
    "# spatial_identifiers = spatial_identifiers.loc[spatial_identifiers['p_value_information'] < 0.05]\n",
    "for i, row in spatial_identifiers.iterrows():\n",
    "    si_done = False\n",
    "    for j, val in remapping_df[remapping_row_identifiers].iterrows():\n",
    "        if list(row[neurofunc_row_identifiers].to_numpy()) == list(val.to_numpy()):\n",
    "            remapping_df.loc[j, 'isSpatial'] = 1\n",
    "            si_done = True\n",
    "    if si_done == False:\n",
    "        print('error spatial')\n",
    "\n",
    "remapping_df['isSparse'] = 0\n",
    "sparsity_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_sparsity'] < 0.05]\n",
    "sparsity_identifiers = sparsity_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# sparsity_identifiers = shuffle_spatial_df.groupby(neurofunc_row_identifiers).agg({'p_value_sparsity': 'first'}).reset_index()\n",
    "# sparsity_identifiers = sparsity_identifiers.loc[sparsity_identifiers['p_value_sparsity'] < 0.05]\n",
    "for i, row in sparsity_identifiers.iterrows():\n",
    "    si_done = False\n",
    "    for j, val in remapping_df[remapping_row_identifiers].iterrows():\n",
    "        if list(row[neurofunc_row_identifiers].to_numpy()) == list(val.to_numpy()):\n",
    "            remapping_df.loc[j, 'isSparse'] = 1\n",
    "            si_done = True\n",
    "    if si_done == False:\n",
    "        print('error sparsity')\n",
    "\n",
    "remapping_df['isSelective'] = 0\n",
    "selectivity_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_selectivity'] < 0.05]\n",
    "selectivity_identifiers = selectivity_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# selectivity_identifiers = shuffle_spatial_df.groupby(neurofunc_row_identifiers).agg({'p_value_selectivity': 'first'}).reset_index()\n",
    "# selectivity_identifiers = selectivity_identifiers.loc[selectivity_identifiers['p_value_selectivity'] < 0.05]\n",
    "for i, row in selectivity_identifiers.iterrows():\n",
    "    si_done = False\n",
    "    for j, val in remapping_df[remapping_row_identifiers].iterrows():\n",
    "        if list(row[neurofunc_row_identifiers].to_numpy()) == list(val.to_numpy()):\n",
    "            remapping_df.loc[j, 'isSelective'] = 1\n",
    "            si_done = True\n",
    "    if si_done == False:\n",
    "        print('error selectivity')\n",
    "\n",
    "remapping_df['isCoherent'] = 0\n",
    "coherence_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_coherence'] < 0.05]\n",
    "coherence_identifiers = coherence_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# coherence_identifiers = shuffle_spatial_df.groupby(neurofunc_row_identifiers).agg({'p_value_coherence': 'first'}).reset_index()\n",
    "# coherence_identifiers = coherence_identifiers.loc[coherence_identifiers['p_value_coherence'] < 0.05]\n",
    "for i, row in coherence_identifiers.iterrows():\n",
    "    si_done = False\n",
    "    for j, val in remapping_df[remapping_row_identifiers].iterrows():\n",
    "        if list(row[neurofunc_row_identifiers].to_numpy()) == list(val.to_numpy()):\n",
    "            remapping_df.loc[j, 'isCoherent'] = 1\n",
    "            si_done = True\n",
    "    if si_done == False:\n",
    "        print('error coherence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "# remapping_df.to_excel('filtered_first_ses_greater.xlsx', index=False)\n",
    "remapping_df.to_excel(r'c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\gar_corrected_combined.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(regular_df), len(sd_df), len(remapping_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "cts = ax.hist(np.log(shuffle_spatial_df['shuffled_information_mean']), bins=100)\n",
    "ax.vlines(np.log(np.mean(shuffle_spatial_df['shuffled_information_mean'])), 0, np.max(cts[0]),color='r')\n",
    "ax.set_xlabel('Shuffled Information Means')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.hist(np.log(shuffle_spatial_df['shuffled_sparsity_mean']), bins=100)\n",
    "ax.set_xlabel('Shuffled Sparsity Means')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.hist(np.log(shuffle_spatial_df['shuffled_selectivity_mean']), bins=100)\n",
    "ax.set_xlabel('Shuffled Selectivity Means')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "ax.hist(np.log(shuffle_spatial_df['shuffled_coherence_mean']), bins=100)\n",
    "ax.set_xlabel('Shuffled Coherence Means')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remapping_df['isSpatial'].value_counts())\n",
    "print(remapping_df['isSparse'].value_counts())\n",
    "print(remapping_df['isSelective'].value_counts())\n",
    "print(remapping_df['isCoherent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_df['isSpatial'].value_counts())\n",
    "print(sd_df['isSparse'].value_counts())\n",
    "print(sd_df['isSelective'].value_counts())\n",
    "print(sd_df['isCoherent'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPRISM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
