{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, mannwhitneyu, wilcoxon, ttest_rel, ttest_ind\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from matplotlib.colors import ColorConverter\n",
    "\n",
    "remap_path = os.getcwd()\n",
    "prototype_path = os.path.abspath(os.path.join(remap_path, os.pardir))\n",
    "project_path = os.path.abspath(os.path.join(prototype_path, os.pardir))\n",
    "lab_path = os.path.abspath(os.path.join(project_path, os.pardir))\n",
    "sys.path.append(project_path)\n",
    "os.chdir(project_path)\n",
    "sys.path.append(project_path)\n",
    "print(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _prototypes.cell_remapping.src.MEC_naming import MEC_naming_format, extract_name_mec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv path\n",
    "remapping_csv_path = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\full_32_permute.xlsx\"\n",
    "\n",
    "# load csv\n",
    "remapping_df = pd.read_excel(remapping_csv_path)\n",
    "\n",
    "# csv path\n",
    "shuffle_spatial_path = r\"C:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit_test_data\\MEC_spatial_shuffles_combined_new.xlsx\"\n",
    "\n",
    "# load csv\n",
    "shuffle_spatial_df = pd.read_excel(shuffle_spatial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle_spatial_df['p_value_information'] = 1 - shuffle_spatial_df['p_value_information']\n",
    "# shuffle_spatial_df['p_value_sparsity'] = 1 - shuffle_spatial_df['p_value_sparsity']\n",
    "# shuffle_spatial_df['p_value_selectivity'] = 1 - shuffle_spatial_df['p_value_selectivity']\n",
    "# shuffle_spatial_df['p_value_coherence'] = 1 - shuffle_spatial_df['p_value_coherence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to match neurofunc and remapping\n",
    "import re\n",
    "from scripts.batch_map.LEC_naming import LEC_naming_format, extract_name_lec\n",
    "\n",
    "def _check_single_format(filename, fformat, fxn):\n",
    "    if re.match(str(fformat), str(filename)) is not None:\n",
    "        return list(fxn(filename))\n",
    "\n",
    "# For neurofunc need to add extract, date, depth, name, stim \n",
    "# iterate thru rows of shuffle_spatial_df and extract from signature\n",
    "for i, row in shuffle_spatial_df.iterrows():\n",
    "    # extract\n",
    "    fname = row['Session']\n",
    "    name = extract_name_mec(fname)\n",
    "    formats = MEC_naming_format\n",
    "    for fformat in list(formats.keys()):\n",
    "        checked = _check_single_format(fname, fformat, formats[fformat])\n",
    "        if checked is not None:\n",
    "            break\n",
    "    stim, depth, name, date = checked\n",
    "    \n",
    "    shuffle_spatial_df.at[i, 'date'] = date\n",
    "    shuffle_spatial_df.at[i, 'depth'] = depth\n",
    "    shuffle_spatial_df.at[i, 'name'] = name\n",
    "    shuffle_spatial_df.at[i, 'stim'] = stim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the common columns\n",
    "neurofunc_row_identifiers = ['name', 'Tetrode', 'Cell ID']\n",
    "remapping_row_identifiers = ['name', 'tetrode', 'unit_id']\n",
    "\n",
    "for row in neurofunc_row_identifiers:\n",
    "    shuffle_spatial_df[row] = shuffle_spatial_df[row].astype(str)\n",
    "for row in remapping_row_identifiers:\n",
    "    remapping_df[row] = remapping_df[row].astype(str)\n",
    "shuffle_spatial_df['Session'] = shuffle_spatial_df['Session'].astype(str)\n",
    "remapping_df['signature'] = remapping_df['signature'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an empty list to store the merged rows\n",
    "merged_rows = []\n",
    "\n",
    "# Iterate through each row in remapping_df\n",
    "counter = 0\n",
    "for remapping_row in remapping_df.itertuples(index=False):\n",
    "    # Extract the identifiers from the remapping row\n",
    "    remapping_identifiers = [getattr(remapping_row, col) for col in remapping_row_identifiers]\n",
    "\n",
    "    # Find the matching row in shuffle_spatial_df based on the identifiers\n",
    "    matching_row = shuffle_spatial_df.loc[\n",
    "        (shuffle_spatial_df[neurofunc_row_identifiers] == remapping_identifiers).all(axis=1)\n",
    "    ]\n",
    "\n",
    "    # Check if a matching row was found\n",
    "    if len(matching_row) == 0:\n",
    "        print(\"Found {} matching rows for {}\".format(len(matching_row), remapping_identifiers))\n",
    "        print(matching_row['Session'], getattr(remapping_row, 'signature'))\n",
    "        # stop()\n",
    "    elif len(matching_row) > 1:\n",
    "        # check all rows are matching on spatial info score \n",
    "        print(matching_row)\n",
    "        prev = None\n",
    "        for i, row in matching_row.iterrows():\n",
    "            if prev is None:\n",
    "                prev = row['spike_count']\n",
    "            else:\n",
    "                if prev != row['spike_count']:\n",
    "                    print('multiple matches')\n",
    "                    print(matching_row)\n",
    "                    # stop()\n",
    "        \n",
    "    # Join the matching rows\n",
    "    # merged_row = pd.concat([matching_row, pd.DataFrame([remapping_row], columns=remapping_df.columns)], axis=1)\n",
    "    merged_rows.append(matching_row)\n",
    "    counter += 1\n",
    "\n",
    "    if len(merged_rows) != counter:\n",
    "        print('error {} != {}'.format(len(merged_rows), counter))\n",
    "        print(matching_row)\n",
    "\n",
    "\n",
    "# Create the merged dataframe\n",
    "merged_df = pd.concat(merged_rows, ignore_index=True)\n",
    "\n",
    "# Print the merged dataframe\n",
    "# print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle_spatial_df['isSpatial'] = 0\n",
    "# spatial_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_information'] < 0.05]\n",
    "# spatial_identifiers = spatial_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# for i, row in spatial_identifiers.iterrows():\n",
    "#     matching_rows = remapping_df[remapping_row_identifiers].eq(row[neurofunc_row_identifiers]).all(axis=1)\n",
    "#     remapping_df.loc[matching_rows, 'isSpatial'] = 1\n",
    "\n",
    "# shuffle_spatial_df['isSparse'] = 0\n",
    "# sparsity_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_sparsity'] < 0.05]\n",
    "# sparsity_identifiers = sparsity_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# for i, row in sparsity_identifiers.iterrows():\n",
    "#     matching_rows = remapping_df[remapping_row_identifiers].eq(row[neurofunc_row_identifiers]).all(axis=1)\n",
    "#     remapping_df.loc[matching_rows, 'isSparse'] = 1\n",
    "\n",
    "# shuffle_spatial_df['isSelective'] = 0\n",
    "# selectivity_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_selectivity'] < 0.05]\n",
    "# selectivity_identifiers = selectivity_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# for i, row in selectivity_identifiers.iterrows():\n",
    "#     matching_rows = remapping_df[remapping_row_identifiers].eq(row[neurofunc_row_identifiers]).all(axis=1)\n",
    "#     remapping_df.loc[matching_rows, 'isSelective'] = 1\n",
    "\n",
    "# shuffle_spatial_df['isCoherent'] = 0\n",
    "# coherence_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_coherence'] < 0.05]\n",
    "# coherence_identifiers = coherence_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "# for i, row in coherence_identifiers.iterrows():\n",
    "#     matching_rows = remapping_df[remapping_row_identifiers].eq(row[neurofunc_row_identifiers]).all(axis=1)\n",
    "#     remapping_df.loc[matching_rows, 'isCoherent'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_id_dict = {}\n",
    "unq_names = shuffle_spatial_df['name'].unique()\n",
    "unq_name_counts = {x:1 for x in unq_names}\n",
    "for ses_id in np.sort(shuffle_spatial_df['Session'].unique()):\n",
    "    nme = ses_id.split('_')[0]\n",
    "    ses_id_dict[ses_id] = 'session_' + str(unq_name_counts[nme])\n",
    "    unq_name_counts[nme] += 1\n",
    "\n",
    "shuffle_spatial_df['session_id'] = ''\n",
    "shuffle_spatial_df['group'] = ''\n",
    "\n",
    "for i in range(len(shuffle_spatial_df)):\n",
    "    shuffle_spatial_df.loc[i,'session_id'] = ses_id_dict[shuffle_spatial_df.iloc[i]['Session']]\n",
    "\n",
    "app_ki = ['1-13', '1-14', '1a27', '1-30', '1a35', '1a37']\n",
    "control = ['1-20', '1-24', '1-25', '1-28', '1-34', '1a23', '1a40']\n",
    "\n",
    "for i in range(len(remapping_df)):\n",
    "    nme = remapping_df.iloc[i]['name']\n",
    "    if nme in control:\n",
    "        remapping_df.loc[i,'group'] = 'control'\n",
    "    else:\n",
    "        assert nme in app_ki\n",
    "        remapping_df.loc[i,'group'] = 'app_ki'\n",
    "    ses1 = eval(remapping_df.iloc[i]['session_ids'])[0]\n",
    "    ses2 = eval(remapping_df.iloc[i]['session_ids'])[1]\n",
    "\n",
    "    ses1_match = shuffle_spatial_df.loc[(shuffle_spatial_df['session_id'] == ses1) & (shuffle_spatial_df['name'] == remapping_df.iloc[i]['name']) & (shuffle_spatial_df['Tetrode'] == remapping_df.iloc[i]['tetrode']) & (shuffle_spatial_df['Cell ID'] == remapping_df.iloc[i]['unit_id'])]\n",
    "    ses2_match = shuffle_spatial_df.loc[(shuffle_spatial_df['session_id'] == ses2) & (shuffle_spatial_df['name'] == remapping_df.iloc[i]['name']) & (shuffle_spatial_df['Tetrode'] == remapping_df.iloc[i]['tetrode']) & (shuffle_spatial_df['Cell ID'] == remapping_df.iloc[i]['unit_id'])]\n",
    "\n",
    "    assert len(ses1_match) == 1, 'ses1_match: {}'.format(len(ses1_match))\n",
    "    assert len(ses2_match) == 1, 'ses2_match: {}'.format(len(ses2_match))\n",
    "\n",
    "    for ky in ['information', 'sparsity', 'selectivity', 'coherence']:\n",
    "        score_origin_session = ses1_match.iloc[0][ky]\n",
    "        score_target_session = ses2_match.iloc[0][ky]\n",
    "        remapping_df.loc[i, ky + '_origin_session'] = score_origin_session\n",
    "        remapping_df.loc[i, ky + '_target_session'] = score_target_session\n",
    "\n",
    "        shuffled_score_mean_origin_session = ses1_match.iloc[0]['shuffled_' + ky + '_mean']\n",
    "        shuffled_score_mean_target_session = ses2_match.iloc[0]['shuffled_' + ky + '_mean']\n",
    "        remapping_df.loc[i, ky + '_reference_mean_origin_session'] = shuffled_score_mean_origin_session\n",
    "        remapping_df.loc[i, ky + '_reference_mean_target_session'] = shuffled_score_mean_target_session\n",
    "\n",
    "        shuffled_score_sd_origin_session = ses1_match.iloc[0]['shuffled_' + ky + '_std']\n",
    "        shuffled_score_sd_target_session = ses2_match.iloc[0]['shuffled_' + ky + '_std']\n",
    "        remapping_df.loc[i, ky + '_reference_sd_origin_session'] = shuffled_score_sd_origin_session\n",
    "        remapping_df.loc[i, ky + '_reference_sd_target_session'] = shuffled_score_sd_target_session\n",
    "\n",
    "        shuffled_score_p_value_origin_session = ses1_match.iloc[0]['p_value_' + ky]\n",
    "        shuffled_score_p_value_target_session = ses2_match.iloc[0]['p_value_' + ky]\n",
    "        remapping_df.loc[i, ky + '_quantile_origin_session'] = shuffled_score_p_value_origin_session\n",
    "        remapping_df.loc[i, ky + '_quantile_target_session'] = shuffled_score_p_value_target_session\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "remapping_df.to_excel('remapping_shuffle_merged.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping_df['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Voronoi\n",
    "\n",
    "# Generate random centroids (x, y positions between 0 and 1)\n",
    "np.random.seed(0)\n",
    "num_centroids = 20\n",
    "centroids = np.random.rand(num_centroids, 2)\n",
    "\n",
    "# Create a grid for visualization\n",
    "x_grid, y_grid = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "grid_points = np.column_stack((x_grid.flatten(), y_grid.flatten()))\n",
    "\n",
    "# Calculate Voronoi diagram\n",
    "vor = Voronoi(centroids)\n",
    "\n",
    "# Get the Voronoi regions and plot them\n",
    "plt.figure(figsize=(8, 8))\n",
    "for region in vor.regions:\n",
    "    if not -1 in region and len(region) > 0:\n",
    "        polygon = [vor.vertices[i] for i in region]\n",
    "        plt.fill(*zip(*polygon), edgecolor='black', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Plot the centroids\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], color='red', marker='o', s=50, label='Initial Centroids')\n",
    "\n",
    "# Plot settings\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title('Centroids Converging to Hexagonal Mesh')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping_df['isSpatial'] = 0\n",
    "\n",
    "# any session pvalue < 0.05 then cell is spatial\n",
    "# spatial_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_information'] < 0.05]\n",
    "# spatial_identifiers = spatial_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "\n",
    "# only first session pvalue < 0.05 then cell is spatial\n",
    "spatial_identifiers = shuffle_spatial_df.groupby(neurofunc_row_identifiers).agg({'p_value_information': 'first'}).reset_index()\n",
    "spatial_identifiers = spatial_identifiers.loc[spatial_identifiers['p_value_information'] < 0.05]\n",
    "for i, row in spatial_identifiers.iterrows():\n",
    "    si_done = False\n",
    "    for j, val in remapping_df[remapping_row_identifiers].iterrows():\n",
    "        if list(row[neurofunc_row_identifiers].to_numpy()) == list(val.to_numpy()):\n",
    "            remapping_df.loc[j, 'isSpatial'] = 1\n",
    "            si_done = True\n",
    "    if si_done == False:\n",
    "        print('error spatial')\n",
    "\n",
    "remapping_df['isSparse'] = 0\n",
    "# sparsity_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_sparsity'] < 0.05]\n",
    "# sparsity_identifiers = sparsity_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "sparsity_identifiers = shuffle_spatial_df.groupby(neurofunc_row_identifiers).agg({'p_value_sparsity': 'first'}).reset_index()\n",
    "sparsity_identifiers = sparsity_identifiers.loc[sparsity_identifiers['p_value_sparsity'] < 0.05]\n",
    "for i, row in sparsity_identifiers.iterrows():\n",
    "    si_done = False\n",
    "    for j, val in remapping_df[remapping_row_identifiers].iterrows():\n",
    "        if list(row[neurofunc_row_identifiers].to_numpy()) == list(val.to_numpy()):\n",
    "            remapping_df.loc[j, 'isSparse'] = 1\n",
    "            si_done = True\n",
    "    if si_done == False:\n",
    "        print('error sparsity')\n",
    "\n",
    "remapping_df['isSelective'] = 0\n",
    "# selectivity_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_selectivity'] < 0.05]\n",
    "# selectivity_identifiers = selectivity_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "selectivity_identifiers = shuffle_spatial_df.groupby(neurofunc_row_identifiers).agg({'p_value_selectivity': 'first'}).reset_index()\n",
    "selectivity_identifiers = selectivity_identifiers.loc[selectivity_identifiers['p_value_selectivity'] < 0.05]\n",
    "for i, row in selectivity_identifiers.iterrows():\n",
    "    si_done = False\n",
    "    for j, val in remapping_df[remapping_row_identifiers].iterrows():\n",
    "        if list(row[neurofunc_row_identifiers].to_numpy()) == list(val.to_numpy()):\n",
    "            remapping_df.loc[j, 'isSelective'] = 1\n",
    "            si_done = True\n",
    "    if si_done == False:\n",
    "        print('error selectivity')\n",
    "\n",
    "remapping_df['isCoherent'] = 0\n",
    "# coherence_filtered = shuffle_spatial_df.loc[shuffle_spatial_df['p_value_coherence'] < 0.05]\n",
    "# coherence_identifiers = coherence_filtered.groupby(neurofunc_row_identifiers).count().reset_index()[neurofunc_row_identifiers]\n",
    "coherence_identifiers = shuffle_spatial_df.groupby(neurofunc_row_identifiers).agg({'p_value_coherence': 'first'}).reset_index()\n",
    "coherence_identifiers = coherence_identifiers.loc[coherence_identifiers['p_value_coherence'] < 0.05]\n",
    "for i, row in coherence_identifiers.iterrows():\n",
    "    si_done = False\n",
    "    for j, val in remapping_df[remapping_row_identifiers].iterrows():\n",
    "        if list(row[neurofunc_row_identifiers].to_numpy()) == list(val.to_numpy()):\n",
    "            remapping_df.loc[j, 'isCoherent'] = 1\n",
    "            si_done = True\n",
    "    if si_done == False:\n",
    "        print('error coherence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "remapping_df.to_excel('filtered_first_ses_greater.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_spatial_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "cts = ax.hist(np.log(shuffle_spatial_df['shuffled_information_mean']), bins=100)\n",
    "ax.vlines(np.log(np.mean(shuffle_spatial_df['shuffled_information_mean'])), 0, np.max(cts[0]),color='r')\n",
    "ax.set_xlabel('Shuffled Information Means')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.hist(np.log(shuffle_spatial_df['shuffled_sparsity_mean']), bins=100)\n",
    "ax.set_xlabel('Shuffled Sparsity Means')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.hist(np.log(shuffle_spatial_df['shuffled_selectivity_mean']), bins=100)\n",
    "ax.set_xlabel('Shuffled Selectivity Means')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "ax.hist(np.log(shuffle_spatial_df['shuffled_coherence_mean']), bins=100)\n",
    "ax.set_xlabel('Shuffled Coherence Means')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remapping_df['isSpatial'].value_counts())\n",
    "print(remapping_df['isSparse'].value_counts())\n",
    "print(remapping_df['isSelective'].value_counts())\n",
    "print(remapping_df['isCoherent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remapping_df['isSpatial'].value_counts())\n",
    "print(remapping_df['isSparse'].value_counts())\n",
    "print(remapping_df['isSelective'].value_counts())\n",
    "print(remapping_df['isCoherent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial_df = remapping_df.groupby(remapping_row_identifiers)\n",
    "# filtered_spatial_df = pd.DataFrame(columns=remapping_df.columns)\n",
    "\n",
    "# for i, grp in spatial_df:\n",
    "#     ses1_p_info = grp['p_value_information'].iloc[0]\n",
    "#     if ses1_p_info < 0.05:\n",
    "#         filtered_spatial_df = filtered_spatial_df.append(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPRISM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
