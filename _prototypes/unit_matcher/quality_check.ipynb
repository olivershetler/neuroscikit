{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ACTIVE JUPYTER NOTEBOOK TO PERFORM QUALITY CONTROL FOLLOWING UNIT MATCHING '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" ACTIVE JUPYTER NOTEBOOK TO PERFORM QUALITY CONTROL FOLLOWING UNIT MATCHING \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\n"
     ]
    }
   ],
   "source": [
    "# Outside imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set necessary paths / make project path = ...../neuroscikit/\n",
    "unit_matcher_path = os.getcwd()\n",
    "prototype_path = os.path.abspath(os.path.join(unit_matcher_path, os.pardir))\n",
    "project_path = os.path.abspath(os.path.join(prototype_path, os.pardir))\n",
    "lab_path = os.path.abspath(os.path.join(project_path, os.pardir))\n",
    "sys.path.append(project_path)\n",
    "os.chdir(project_path)\n",
    "print(project_path)\n",
    "\n",
    "# Internal imports\n",
    "\n",
    "# Read write modules\n",
    "from x_io.rw.axona.batch_read import make_study\n",
    "from _prototypes.unit_matcher.read_axona import read_sequential_sessions, temp_read_cut\n",
    "from _prototypes.unit_matcher.write_axona import format_new_cut_file_name\n",
    "\n",
    "# Unit matching modules\n",
    "from _prototypes.unit_matcher.main import format_cut, run_unit_matcher, map_unit_matches_first_session, map_unit_matches_sequential_session\n",
    "from _prototypes.unit_matcher.session import compare_sessions\n",
    "from _prototypes.unit_matcher.waveform import time_index, derivative, derivative2, morphological_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" If a setting is not used for your analysis (e.g. smoothing_factor), just pass in an arbitrary value or pass in 'None' \"\"\"\n",
    "STUDY_SETTINGS = {\n",
    "\n",
    "    'ppm': 511,  # EDIT HERE\n",
    "\n",
    "    'smoothing_factor': None, # EDIT HERE\n",
    "\n",
    "    'useMatchedCut': False,  # EDIT HERE, set to False if you want to use runUnitMatcher, set to True after to load in matched.cut file\n",
    "}\n",
    "\n",
    "\n",
    "# Switch devices to True/False based on what is being used (to be extended for more devices in future)\n",
    "device_settings = {'axona_led_tracker': True, 'implant': True} \n",
    "\n",
    "# Make sure implant metadata is correct, change if not, AT THE MINIMUM leave implant_type: tetrode\n",
    "implant_settings = {'implant_type': 'tetrode', 'implant_geometry': 'square', 'wire_length': 25, 'wire_length_units': 'um', 'implant_units': 'uV'}\n",
    "\n",
    "# WE ASSUME DEVICE AND IMPLANT SETTINGS ARE CONSISTENCE ACROSS SESSIONS, IF THIS IS NOT THE CASE PLEASE LET ME KNOW\n",
    "\n",
    "# Set channel count + add device/implant settings\n",
    "SESSION_SETTINGS = {\n",
    "    'channel_count': 4, # EDIT HERE, default is 4, you can change to other number but code will check how many tetrode files are present and set that to channel copunt regardless\n",
    "    'devices': device_settings, # EDIT HERE\n",
    "    'implant': implant_settings, # EDIT HERE\n",
    "}\n",
    "\n",
    "STUDY_SETTINGS['session'] = SESSION_SETTINGS\n",
    "\n",
    "settings_dict = STUDY_SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MAKE DATA DIR THE SAME PATH AS THE ONE USED IN THE UNIT MATCHER \"\"\"\n",
    "\n",
    "# Note: if you only want to verify a certain amount of sessions from the full unit matching process \n",
    "# 1) either make a separate folder with only the tetrode files (+ set + pos + cut + matched.cut) that you want to look at \n",
    "# 2) or load in the full study and use session id/animal id to pull out the speciffic sessions you want \n",
    "# (if too difficult can add a function to take a file path or id and return the session in question)\n",
    "data_dir = lab_path + r'\\neuroscikit_test_data\\20180502-ROUND-3000'\n",
    "# data_dir = lab_path + r'\\neuroscikit_test_data\\single_sequential'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n"
     ]
    }
   ],
   "source": [
    "settings_dict_unmatched = settings_dict\n",
    "settings_dict_unmatched['useMatchedCut'] = False\n",
    "\n",
    "# unmatched_study = make_study([data_dir], settings_dict_unmatched, method='MSD')\n",
    "unmatched_study = make_study([data_dir], settings_dict_unmatched, method='JSD')\n",
    "unmatched_study.make_animals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Animal ID set\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n",
      "Session data added, spikes sorted by cell\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 43938 is out of bounds for axis 0 with size 43847",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\_prototypes\\unit_matcher\\quality_check.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aaoun/OneDrive%20-%20cumc.columbia.edu/Desktop/HussainiLab/neuroscikit/_prototypes/unit_matcher/quality_check.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m settings_dict_matched[\u001b[39m'\u001b[39m\u001b[39museMatchedCut\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aaoun/OneDrive%20-%20cumc.columbia.edu/Desktop/HussainiLab/neuroscikit/_prototypes/unit_matcher/quality_check.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m matched_study \u001b[39m=\u001b[39m make_study([data_dir], settings_dict_matched)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aaoun/OneDrive%20-%20cumc.columbia.edu/Desktop/HussainiLab/neuroscikit/_prototypes/unit_matcher/quality_check.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m matched_study\u001b[39m.\u001b[39;49mmake_animals()\n",
      "File \u001b[1;32mc:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\library\\study_space.py:228\u001b[0m, in \u001b[0;36mStudy.make_animals\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m animal_sessions:\n\u001b[0;32m    227\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(animal_sessions[key]) \u001b[39m==\u001b[39m \u001b[39mdict\u001b[39m\n\u001b[1;32m--> 228\u001b[0m     animal_instance \u001b[39m=\u001b[39m Animal(animal_sessions[key])\n\u001b[0;32m    229\u001b[0m     animals\u001b[39m.\u001b[39mappend(animal_instance)\n\u001b[0;32m    230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manimals \u001b[39m=\u001b[39m animals\n",
      "File \u001b[1;32mc:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\library\\study_space.py:269\u001b[0m, in \u001b[0;36mAnimal.__init__\u001b[1;34m(self, input_dict)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dict \u001b[39m=\u001b[39m input_dict\n\u001b[0;32m    267\u001b[0m \u001b[39m# self.cell_ids = {}\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msessions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensembles \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_input_dict()\n\u001b[0;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation \u001b[39m=\u001b[39m CellPopulation()\n\u001b[0;32m    273\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manimal_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msessions[\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msessions\u001b[39m.\u001b[39mkeys())[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39manimal_id\n",
      "File \u001b[1;32mc:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\library\\study_space.py:284\u001b[0m, in \u001b[0;36mAnimal._read_input_dict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(session, Session)\n\u001b[0;32m    282\u001b[0m \u001b[39m# session is instance of SessionWorkspace, has SessionData and SessionMetadata\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39m# AnimalSession will hold Cells which hold SpikeTrains from SessionData\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m cell_ensemble, cell_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_session(session)\n\u001b[0;32m    285\u001b[0m sessions[key] \u001b[39m=\u001b[39m session\n\u001b[0;32m    286\u001b[0m ensembles[key] \u001b[39m=\u001b[39m cell_ensemble\n",
      "File \u001b[1;32mc:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\library\\study_space.py:320\u001b[0m, in \u001b[0;36mAnimal._read_session\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(spike_cluster, SpikeClusterBatch)\n\u001b[0;32m    319\u001b[0m \u001b[39m# assert isinstance(spike_cluster, SpikeTrainBatch)\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m good_sorted_cells, good_sorted_waveforms, good_clusters, good_label_ids \u001b[39m=\u001b[39m sort_spikes_by_cell(spike_cluster)\n\u001b[0;32m    321\u001b[0m \u001b[39m# spike_train.set_sorted_label_ids(good_label_ids)\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSession data added, spikes sorted by cell\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aaoun\\OneDrive - cumc.columbia.edu\\Desktop\\HussainiLab\\neuroscikit\\library\\spike\\sort_spikes_by_cell.py:43\u001b[0m, in \u001b[0;36msort_spikes_by_cell\u001b[1;34m(clusters)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m lbl \u001b[39min\u001b[39;00m unique_labels:\n\u001b[0;32m     42\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(cluster_labels \u001b[39m==\u001b[39m lbl)[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 43\u001b[0m     spks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(spike_times)[idx]\n\u001b[0;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(spks) \u001b[39m==\u001b[39m \u001b[39mfloat\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(spks) \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64:\n\u001b[0;32m     45\u001b[0m         spks \u001b[39m=\u001b[39m [spks]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 43938 is out of bounds for axis 0 with size 43847"
     ]
    }
   ],
   "source": [
    "# To use for loading in matched cut and vizualizing / subsequent analysis\n",
    "settings_dict_matched = settings_dict\n",
    "settings_dict_matched['useMatchedCut'] = True\n",
    "\n",
    "matched_study = make_study([data_dir], settings_dict_matched)\n",
    "matched_study.make_animals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_study_animal_ids = matched_study.animal_ids\n",
    "unmatched_study_animal_ids = unmatched_study.animal_ids\n",
    "matched_study_animals = matched_study.animals\n",
    "unmatched_study_animals = unmatched_study.animals\n",
    "\n",
    "print('Matched Animal IDs:' + str(sorted(matched_study_animal_ids)))\n",
    "print('Unmatched Animal IDs: ' + str(sorted(unmatched_study_animal_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = ['b', 'lightgreen', 'r', 'purple', 'cyan', 'darkgreen', 'brown', 'aquamarine', 'indigo', 'gold', 'maroon', 'yellow', 'grey', 'lightblue', 'pink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _prototypes.unit_matcher.write_axona import apply_remapping, write_cut\n",
    "\n",
    "\n",
    "def qualityCheck(matched_study, unmatched_study):\n",
    "\n",
    "    print(matched_study.animal_ids)\n",
    "    animal_id_to_use = str(input('Choose animal id from printed options'))\n",
    "    idx = np.where(animal_id_to_use in matched_study.animal_ids)[0][0]\n",
    "    print('Animal Sessions: ' + str(np.asarray(matched_study.animals)[idx].sessions.keys()))\n",
    "    ses1_id = str(input('Choose first session id from animal sessions'))\n",
    "    ses2_id = str(input('Choose second session id from animal sessions'))\n",
    "\n",
    "\n",
    "    # animal_id_to_use = '20180502-ROUND-3000_tet1'\n",
    "    # ses1_id = 'session_1'\n",
    "    # ses2_id = 'session_2'\n",
    "\n",
    "    unmatched_animal = unmatched_study.get_animal_by_id(animal_id_to_use)\n",
    "    matched_animal = matched_study.get_animal_by_id(animal_id_to_use)\n",
    "    # unmatched_animal = np.asarray(unmatched_study.animals)[idx]\n",
    "    # matched_animal = np.asarray(matched_study.animals)[idx]\n",
    "\n",
    "    ses1_unmatched = unmatched_animal.sessions[ses1_id]\n",
    "    ses2_unmatched = unmatched_animal.sessions[ses2_id]\n",
    "\n",
    "    ses1_matched = matched_animal.sessions[ses1_id]\n",
    "    ses2_matched = matched_animal.sessions[ses2_id]\n",
    "\n",
    "    ses1_new_cut = ses1_matched.session_metadata.file_paths['cut']\n",
    "    ses2_new_cut = ses1_matched.session_metadata.file_paths['cut']\n",
    "\n",
    "    ses1_old_cells = ses1_unmatched.get_cell_data()['cell_ensemble']\n",
    "    ses2_old_cells = ses2_unmatched.get_cell_data()['cell_ensemble']\n",
    "\n",
    "    ses1_new_cells = ses1_matched.get_cell_data()['cell_ensemble']\n",
    "    ses2_new_cells = ses2_matched.get_cell_data()['cell_ensemble']\n",
    "\n",
    "    assert len(ses1_old_cells.cells) == len(ses1_new_cells.cells)\n",
    "    assert len(ses2_old_cells.cells) == len(ses2_new_cells.cells)\n",
    "\n",
    "    col_count = 5\n",
    "    row_count = 4\n",
    "\n",
    "    make_plot(ses1_unmatched, ses1_old_cells, row_count, col_count, 'Session 1 Pre-Matching')\n",
    "    make_plot(ses2_unmatched, ses2_old_cells, row_count, col_count, 'Session 2 Pre-Matching')\n",
    "    make_plot(ses1_matched, ses1_new_cells, row_count, col_count, 'Session 1 Post-Matching')\n",
    "    make_plot(ses2_matched, ses2_new_cells, row_count, col_count, 'Session 2 Post-Matching')\n",
    "\n",
    "    answer = str(input('Would you like to swap any cell labels? Answer Y/N'))\n",
    "    proceed = False\n",
    "    if answer == 'Y' or answer == 'Yes' or answer == 'y' or answer == 'yes':\n",
    "        proceed = True\n",
    "    if proceed == True:\n",
    "        session_answer = str(input('Enter the session_id that holds the cells'))\n",
    "        cell_1 = str(input('Enter the NEW cell label of the first cell you would like to change'))\n",
    "        cell_2 = str(input('Enter the NEW cell label of the second cell you would like to change'))\n",
    "\n",
    "        chosen_session = matched_animal.sessions[session_answer]\n",
    "\n",
    "        chosen_session = matched_animal.sessions[session_answer]\n",
    "\n",
    "        map_dict = {}\n",
    "        for cell in chosen_session.get_cell_data()['cell_ensemble'].cells:\n",
    "            if int(cell.cluster) == int(cell_1):\n",
    "                map_dict[int(cell_1)] == int(cell_2)\n",
    "            elif cell.cluster == cell_2:\n",
    "                map_dict[int(cell_2)] == int(cell_1)\n",
    "            else:\n",
    "                map_dict[int(cell.cluster)] = int(cell.cluster)\n",
    "        print(map_dict)\n",
    "        matched_cut_file_path, new_data, header_data = format_cut(chosen_session, map_dict)\n",
    "        write_cut(matched_cut_file_path, new_data, header_data)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def make_plot(ses, ensemble, row_count, col_count, title):\n",
    "\n",
    "\n",
    "    figSes = plt.figure(figsize=(18, 5))\n",
    "    figSes.suptitle(title)\n",
    "    for i in range(len(ensemble.cells)):\n",
    "        cell = ensemble.cells[i]\n",
    "        waveforms = cell.signal\n",
    "\n",
    "        mn = np.min(waveforms)\n",
    "        mx = np.max(waveforms)\n",
    "\n",
    "        for k in range(len(cell.signal[0])):\n",
    "            axOldSes1 = figSes.add_subplot(int(np.ceil(len(ensemble.cells) / col_count) * row_count), col_count, int(i + 1 + k * col_count))\n",
    "            channel_signal = waveforms[:,int(k),:]\n",
    "            avg_signal = np.mean(channel_signal, axis=0)\n",
    "            # axOldSes1.plot(channel_signal.T, color='gray', lw=0.5, alpha=0.3)\n",
    "            axOldSes1.plot(avg_signal, color=all_colors[i], lw=2)\n",
    "            axOldSes1.set_title('Cell ' + str(i+1) + ', Channel ' + str(k+1) + ', Spk Count ' + str(len(cell.event_times)))\n",
    "\n",
    "    figSes.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualityCheck(matched_study, unmatched_study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "271de3eaf5512a01a3a2cea9253de8f7a978ec97e5a00bc2131d971ee349090f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
