{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outside imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set necessary paths / make project path = ...../neuroscikit/\n",
    "unit_matcher_path = os.getcwd()\n",
    "prototype_path = os.path.abspath(os.path.join(unit_matcher_path, os.pardir))\n",
    "project_path = os.path.abspath(os.path.join(prototype_path, os.pardir))\n",
    "lab_path = os.path.abspath(os.path.join(project_path, os.pardir))\n",
    "out_path = os.path.abspath(os.path.join(lab_path, os.pardir))\n",
    "sys.path.append(project_path)\n",
    "os.chdir(project_path)\n",
    "print(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal imports\n",
    "\n",
    "# Read write modules\n",
    "from x_io.rw.axona.batch_read import make_study\n",
    "from _prototypes.unit_matcher.read_axona import read_sequential_sessions, temp_read_cut\n",
    "from _prototypes.unit_matcher.write_axona import format_new_cut_file_name\n",
    "\n",
    "# Unit matching modules\n",
    "from _prototypes.unit_matcher.main import format_cut, run_unit_matcher, map_unit_matches_first_session, map_unit_matches_sequential_session\n",
    "from _prototypes.unit_matcher.session import compare_sessions\n",
    "from _prototypes.unit_matcher.waveform import time_index, derivative, derivative2, morphological_points\n",
    "\n",
    "# External imports\n",
    "\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Poisson, Gaussian\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.genmod.families.links import identity, log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" If a setting is not used for your analysis (e.g. smoothing_factor), just pass in an arbitrary value or pass in 'None' \"\"\"\n",
    "STUDY_SETTINGS = {\n",
    "\n",
    "    'ppm': 511,  # EDIT HERE\n",
    "\n",
    "    'smoothing_factor': None, # EDIT HERE\n",
    "\n",
    "    'useMatchedCut': False,  # EDIT HERE, set to False if you want to use runUnitMatcher, set to True after to load in matched.cut file\n",
    "}\n",
    "\n",
    "\n",
    "# Switch devices to True/False based on what is used in the acquisition (to be extended for more devices in future)\n",
    "device_settings = {'axona_led_tracker': True, 'implant': True} \n",
    "\n",
    "# Make sure implant metadata is correct, change if not, AT THE MINIMUM leave implant_type: tetrode\n",
    "implant_settings = {'implant_type': 'tetrode', 'implant_geometry': 'square', 'wire_length': 25, 'wire_length_units': 'um', 'implant_units': 'uV'}\n",
    "\n",
    "# WE ASSUME DEVICE AND IMPLANT SETTINGS ARE CONSISTENCE ACROSS SESSIONS\n",
    "\n",
    "# Set channel count + add device/implant settings\n",
    "SESSION_SETTINGS = {\n",
    "    'channel_count': 4, # EDIT HERE, default is 4, you can change to other number but code will check how many tetrode files are present and set that to channel copunt regardless\n",
    "    'devices': device_settings, # EDIT HERE\n",
    "    'implant': implant_settings, # EDIT HERE\n",
    "}\n",
    "\n",
    "STUDY_SETTINGS['session'] = SESSION_SETTINGS\n",
    "\n",
    "settings_dict = STUDY_SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = lab_path + r'\\neuroscikit_test_data\\20180530-ROUND-3300-1X2B3A' \n",
    "data_dir = lab_path + r'\\neuroscikit_test_data\\LEC_odor\\AD\\Odor_119a-6' \n",
    "\n",
    "\n",
    "# To use in unit matching\n",
    "settings_dict_unmatched = settings_dict\n",
    "settings_dict_unmatched['useMatchedCut'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = make_study([data_dir], settings_dict_unmatched)\n",
    "study.make_animals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_times_to_count(event_times, T):\n",
    "    dt = 0.5\n",
    "    new_time_index = np.arange(0,T,dt)\n",
    "    ct, bins = np.histogram(event_times, bins=new_time_index)\n",
    "    # print(ct.shape, bins[:-1].shape)\n",
    "    return ct, bins[:-1]\n",
    "\n",
    "def aggregate_cell_trials(agg_events, agg_event_objects, trial_start_times, trial_length, trial_ids):\n",
    "    def _filtEvent(x, event_time, start, end):\n",
    "        if event_time>= start and event_time < end:\n",
    "            return x\n",
    "        \n",
    "    sequential_trials = []\n",
    "    trial_dict = {}\n",
    "    # for cell\n",
    "    for i in range(len(agg_events)):\n",
    "        trial_dict[i] = {}\n",
    "        trial_dict[i]['obj'] = {}\n",
    "        trial_dict[i]['data'] = {}\n",
    "\n",
    "        cell_trials = []\n",
    "        # for trial type\n",
    "        for k in range(len(trial_start_times)):\n",
    "            start = trial_start_times[k]\n",
    "            end = trial_start_times[k] + trial_length\n",
    "            trial_id = trial_ids[k]\n",
    "            trial_dict[i]['data'][trial_id] = []\n",
    "            trial_dict[i]['obj'][trial_id] = []\n",
    "\n",
    "            # for ses that has cell\n",
    "            for j in range(len(agg_events[i])):\n",
    "                ses_events = agg_events[i][j]\n",
    "                ids = np.array(list(map(lambda x: _filtEvent(x,ses_events[x],start,end), np.arange(0, len(ses_events), 1))))\n",
    "                ids = ids[ids != None]\n",
    "                # print(ids)\n",
    "                ct, new_time_index = event_times_to_count(np.array(agg_events[i][j])[np.array(ids, dtype=np.int32)], trial_length)\n",
    "\n",
    "                obj = agg_event_objects[i][j]                                        \n",
    "\n",
    "                trial_dict[i]['data'][trial_id].append(ct)\n",
    "                trial_dict[i]['obj'][trial_id].append(obj)\n",
    "\n",
    "                cell_trials = np.hstack((cell_trials, ct))\n",
    "\n",
    "        sequential_trials.append(cell_trials)\n",
    "\n",
    "    return np.array(sequential_trials), trial_dict, np.array(new_time_index)\n",
    "                \n",
    "\n",
    "def aggregate_event_times_matched(study):\n",
    "    agg_events = []\n",
    "    agg_event_objects = []\n",
    "    agg_events_binary = []\n",
    "    prev_time_index = None\n",
    "    for animal in study.animals:\n",
    "\n",
    "        max_matched_cell_count = len(animal.sessions[sorted(list(animal.sessions.keys()))[-1]].get_cell_data()['cell_ensemble'].cells)\n",
    "        # print(max_matched_cell_count)\n",
    "        for k in range(int(max_matched_cell_count)):\n",
    "            cell_label = k + 1\n",
    "            cell_events = []\n",
    "            cell_event_objects = []\n",
    "            cell_events_binary = []\n",
    "            for i in range(len(list(animal.sessions.keys()))):\n",
    "                seskey = 'session_' + str(i+1)\n",
    "                ses = animal.sessions[seskey]\n",
    "                ensemble = ses.get_cell_data()['cell_ensemble']\n",
    "                if cell_label in ensemble.get_cell_label_dict():\n",
    "                    cell = ensemble.get_cell_by_id(cell_label)\n",
    "                    cell_events.append(cell.event_times)\n",
    "                    cell_event_objects.append(cell)\n",
    "                    ct, time_index = event_times_to_count(cell.event_times, cell.cluster.time_index[-1])\n",
    "                    if prev_time_index is not None:\n",
    "                        assert time_index.all() == prev_time_index.all()\n",
    "                    cell_events_binary.append(ct)\n",
    "                    prev_time_index = time_index\n",
    "            agg_events.append(cell_events)\n",
    "            agg_event_objects.append(cell_event_objects)\n",
    "            agg_events_binary.append(cell_events_binary)\n",
    "\n",
    "    # agg_events saves as (cell, sessions_cell_is_in, event_times)\n",
    "    return agg_events, np.array(agg_event_objects), np.array(agg_events_binary), np.array(time_index)\n",
    "\n",
    "def get_time_regressors(time_index, trial_start_times, trial_length):\n",
    "    session_ramping = time_index\n",
    "\n",
    "    dt = time_index[1] - time_index[0]\n",
    "\n",
    "    trial_ramping = []\n",
    "    for i in range(len(trial_start_times)):\n",
    "        ramp = np.arange(0,trial_length, dt)\n",
    "        trial_ramping = np.hstack((trial_ramping, ramp))\n",
    "\n",
    "    if len(trial_ramping) < len(session_ramping):\n",
    "        trial_ramping = np.hstack((trial_ramping, np.arange(0, session_ramping[-1]-trial_start_times[-1]-60+dt, dt)))\n",
    "\n",
    "    return session_ramping, trial_ramping\n",
    "\n",
    "def get_odor_regressors(time_index, odor_labels, odor_presentation_times, odor_window, trial_length):\n",
    "    odor_pulses = []\n",
    "\n",
    "    post_odor_window = []\n",
    "\n",
    "    for i in range(len(odor_labels)):\n",
    "        pulse = np.zeros(len(time_index))\n",
    "        post_pulse = np.zeros(len(time_index))\n",
    "        for j in range(len(odor_presentation_times)):\n",
    "            # print(np.where(np.array(time_index) >=  float(odor_presentation_times[j] + odor_window))[0], np.where(np.array(time_index) < float(odor_presentation_times[j] + odor_window))[0])\n",
    "            end_post = np.where(np.array(time_index) >=  float(odor_presentation_times[j] + odor_window))[0][0]\n",
    "            start = np.where(np.array(time_index) >= float(odor_presentation_times[j]))[0][0]\n",
    "            end = np.where(np.array(time_index) < float(odor_presentation_times[j]) + odor_window)[0][-1]\n",
    "\n",
    "            pulse[start:end] = 1\n",
    "\n",
    "            post_pulse[end : end_post] = 1\n",
    "            \n",
    "        odor_pulses.append(pulse)\n",
    "        post_odor_window.append(post_pulse)\n",
    "\n",
    "    return odor_pulses, post_odor_window\n",
    "\n",
    "def collect_synth_regressors(time_index):\n",
    "\n",
    "    session_ramping, trial_ramping = get_time_regressors(time_index, [0,60,120,180], 60)\n",
    "\n",
    "    odor_pulses, post_odor_window = get_odor_regressors(time_index, ['X','B', 'A', 'X'], [0,60,120,180], 10, 60)\n",
    "\n",
    "    regs = np.vstack((session_ramping, trial_ramping, odor_pulses, post_odor_window))\n",
    "    reg_labels = ['sessionT', 'trialT', 'odorX', 'odorB']\n",
    "\n",
    "    return np.array(regs)\n",
    "\n",
    "def split_test_train(data, percentage=0.70):\n",
    "    \n",
    "    idx = int(percentage * data.shape[1])\n",
    "\n",
    "    train = data[:idx]\n",
    "    test = data[idx:]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def split_endog_exog(y, X, p):\n",
    "    idx = int(p * y.shape[0])\n",
    "\n",
    "    trainY = y[:idx]\n",
    "    testY = y[idx:]\n",
    "    print(X.shape, y.shape, idx)\n",
    "    trainX = X[:,:idx]\n",
    "    testX = X[:,idx:]\n",
    "\n",
    "    print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "    return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg_event_times, agg_event_objects, agg_events_binary, time_index = aggregate_event_times_matched(study)\n",
    "\n",
    "sequential_trials, trial_dict, new_time_index = aggregate_cell_trials(agg_event_times, agg_event_objects, [0,60,120,180], 60, ['O','B', 'A', 'X'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(sequential_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPRISM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "271de3eaf5512a01a3a2cea9253de8f7a978ec97e5a00bc2131d971ee349090f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
